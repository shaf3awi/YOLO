import os
import json
from datetime import datetime
from statistics import mean
import argparse
import numpy as np
import matplotlib
matplotlib.use('Agg')
from matplotlib import pyplot as plt
import torch
import torch.optim as optim
from torch.autograd import Variable
import torch.nn.functional as F
import torch
import torch.nn as nn
import torch.nn.init as init
import pandas as pd
s=pd.read_csv(r'C:\Users\elshaa6\Desktop\PHD\hesham\facial landmarks.csv', header=None, nrows=122)
s.head
s.columns = ['gaze','frames']
s.head
import numpy as np
s.index = np.arange(1, len(s)+1)
data_frame=pd.read_csv(r'C:\Users\elshaa6\Desktop\PHD\hesham\export_dataframe.csv', nrows=598)
data_frame.head
data_frame=data_frame.loc[data_frame.index.repeat(data_frame.frames)]
data_frame.head
data_frame.index = np.arange(1, len(data_frame)+1)
data_frame.head
gaze=pd.read_csv(r'C:\Users\elshaa6\Desktop\PHD\hesham\gaze.csv', nrows=598)

gaze.head
gaze.index = np.arange(1, len(gaze)+1)
gaze.head
gaze['filename'].loc[1:9] ='0' + '0'+ gaze['filename'].astype(str) + '.jpg'

print(gaze)


gaze['filename'].loc[10:99] ='0'+gaze['filename'].astype(str)+ '.jpg'

print(gaze)


gaze['filename'].loc[100:598] =gaze['filename'].astype(str)+ '.jpg'

print(gaze)

gaze.to_csv (r'C:\Users\elshaa6\Desktop\PHD\hesham\gaze2.csv', index = True, header=True)






class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, csv_path, images_folder, transform = None):
        self.df = pd.read_csv(csv_path)
        self.images_folder = images_folder
        self.transform = transform
        self.label = ['center', 'in car', 'left', 'right', 'up', 'down', 'up-left', 'up-right', 'down-left', 'down-right', 'outside right', 'outside left']

    def __len__(self):
        return len(self.df)
    def __getitem__(self, index):
        filename,label= self.df.loc[index]
        #filename = self.df[[index, "filename"]]
        #label = self.label[self.df[index, "label"]]
        image = PIL.Image.open(os.path.join(self.images_folder, filename))
        if self.transform is not None:
            image = self.transform(image)
        return image, label
        
        
train_dataset = CustomDataset(r"C:\Users\elshaa6\Desktop\PHD\hesham\gaze2.csv", r"C:\Users\elshaa6\Desktop\PHD\hesham\madinet nasr - 3"  )


import PIL
for image in train_dataset:
    plt.imshow(image)
    plt.title(label)
    plt.show()
    plt.pause(1)
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
####### network section    
    
    
    
    import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.nn.init as init

from utils import weights_init_normal


class ResidualBlock(nn.Module):
    def __init__(self, in_features):
        super(ResidualBlock, self).__init__()

        conv_block = [  nn.ReflectionPad2d(1),
                        nn.Conv2d(in_features, in_features, 3),
                        nn.InstanceNorm2d(in_features),
                        nn.ReLU(inplace=True),
                        nn.ReflectionPad2d(1),
                        nn.Conv2d(in_features, in_features, 3),
                        nn.InstanceNorm2d(in_features)  ]

        self.conv_block = nn.Sequential(*conv_block)

    def forward(self, x):
        return x + self.conv_block(x)

class Generator(nn.Module):
    def __init__(self, input_nc, output_nc, n_residual_blocks=9):
        super(Generator, self).__init__()

        # Initial convolution block       
        model = [   nn.ReflectionPad2d(3),
                    nn.Conv2d(input_nc, 64, 7),
                    nn.InstanceNorm2d(64),
                    nn.ReLU(inplace=True) ]

        # Downsampling
        in_features = 64
        out_features = in_features*2
        for _ in range(2):
            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),
                        nn.InstanceNorm2d(out_features),
                        nn.ReLU(inplace=True) ]
            in_features = out_features
            out_features = in_features*2

        # Residual blocks
        for _ in range(n_residual_blocks):
            model += [ResidualBlock(in_features)]

        # Upsampling
        out_features = in_features//2
        for _ in range(2):
            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),
                        nn.InstanceNorm2d(out_features),
                        nn.ReLU(inplace=True) ]
            in_features = out_features
            out_features = in_features//2

        # Output layer
        model += [  nn.ReflectionPad2d(3),
                    nn.Conv2d(64, output_nc, 7),
                    nn.Tanh() ]

        self.model = nn.Sequential(*model)
        self.apply(weights_init_normal)

    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self, input_nc):
        super(Discriminator, self).__init__()

        # A bunch of convolutions one after another
        # 256 x 256
        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),
                    nn.LeakyReLU(0.2, inplace=True) ]

        # 128 x 128
        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),
                    nn.InstanceNorm2d(128), 
                    nn.LeakyReLU(0.2, inplace=True) ]

        # 64 x 64
        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),
                    nn.InstanceNorm2d(256), 
                    nn.LeakyReLU(0.2, inplace=True) ]

        # 32 x 32
        model += [  nn.Conv2d(256, 512, 4, stride=1, padding=1),
                    nn.InstanceNorm2d(512), 
                    nn.LeakyReLU(0.2, inplace=True) ]

        # FCN classification layer
        # 31 x 31
        model += [nn.Conv2d(512, 1, 4, stride=1, padding=1)]

        # 30 x 30
        self.model = nn.Sequential(*model)
        self.apply(weights_init_normal)

    def forward(self, x):
        x = self.model(x)
        # Average pooling and flatten
        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1, 1, 1)
        # Do not flatten i.e. PatchGAN
        #return x

class Fire(nn.Module):
    def __init__(self, inplanes, squeeze_planes,
                 expand1x1_planes, expand3x3_planes):
        super(Fire, self).__init__()
        self.inplanes = inplanes
        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)
        self.squeeze_activation = nn.ReLU(inplace=True)
        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,
                                   kernel_size=1)
        self.expand1x1_activation = nn.ReLU(inplace=True)
        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,
                                   kernel_size=3, padding=1)
        self.expand3x3_activation = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.squeeze_activation(self.squeeze(x))
        return torch.cat([
            self.expand1x1_activation(self.expand1x1(x)),
            self.expand3x3_activation(self.expand3x3(x))
        ], 1)

class SqueezeNet(nn.Module):
    def __init__(self, version='1_0', num_classes=9):
        super(SqueezeNet, self).__init__()
        self.num_classes = num_classes
        self.version = version
        if version == '1_0':
            self.features = nn.Sequential(
                nn.Conv2d(3, 96, kernel_size=7, stride=2),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
                Fire(96, 16, 64, 64),
                Fire(128, 16, 64, 64),
                Fire(128, 32, 128, 128),
                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
                Fire(256, 32, 128, 128),
                Fire(256, 48, 192, 192),
                Fire(384, 48, 192, 192),
                Fire(384, 64, 256, 256),
                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
                Fire(512, 64, 256, 256))
            # Final convolution is initialized differently from the rest
            final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)
            self.cams = nn.Sequential(
                nn.Dropout(p=0.5),
                final_conv,
                nn.ReLU(inplace=True))
            self.classifier = nn.Sequential(
                nn.AdaptiveAvgPool2d((1, 1)),
                nn.LogSoftmax(dim=1))
        elif version == '1_1':
            self.features = nn.Sequential(
                nn.Conv2d(3, 64, kernel_size=3, stride=2),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
                Fire(64, 16, 64, 64),
                Fire(128, 16, 64, 64),
                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
                Fire(128, 32, 128, 128),
                Fire(256, 32, 128, 128),
                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
                Fire(256, 48, 192, 192),
                Fire(384, 48, 192, 192),
                Fire(384, 64, 256, 256),
                Fire(512, 64, 256, 256))
            # Final convolution is initialized differently from the rest
            final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)
            self.cams = nn.Sequential(
                nn.Dropout(p=0.5),
                final_conv,
                nn.ReLU(inplace=True))
            self.classifier = nn.Sequential(
                nn.AdaptiveAvgPool2d((1, 1)),
                nn.LogSoftmax(dim=1))
        else:
            raise ValueError("Unsupported SqueezeNet version {version}:"
                             "1_0/1_1 expected".format(version=version))

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                if m is final_conv:
                    init.normal_(m.weight, mean=0.0, std=0.01)
                else:
                    init.kaiming_uniform_(m.weight)
                if m.bias is not None:
                    init.constant_(m.bias, 0)

    def forward(self, x):
        x = self.features(x)
        masks = self.cams(x)
        x = self.classifier(masks)
        return x, masks
